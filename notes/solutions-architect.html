<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>Solutions Architect</title>
    <style>
      * {
        box-sizing: border-box;
      }

      div {
        margin: 0.2em 0;
        padding: 0;
      }
      table {
        width: 100%;
      }

      table,
      td,
      tr,
      th {
        position: relative;
        border: 1px solid black;
        border-collapse: collapse;
      }

      th {
        padding: 0.8em;
        text-transform: uppercase;
        background-color: black;
        color: white;
      }
      tbody > tr:nth-child(odd) {
        background-color: gray;
      }
      tbody > tr:nth-child(even) {
        background-color: gray;
        opacity: 0.8;
      }
      tbody > tr:hover {
        background-color: white;
      }
      #inputCuenta {
        width: 30%;
        margin: 0;
        padding: 0.5em 0;
      }
      #inputDetalle {
        width: 60%;
        margin: 0;
        padding: 0.5em 0;
      }
      button {
        width: 9%;
        margin: 0;
        padding: 0.5em 0;
      }
      tr > td:first-child {
        text-align: center;
        text-transform: uppercase;
        font-weight: bold;
        width: 17.5%;
      }
      tr > td:last-child {
        width: 32.5%;
      }
      tr > td {
        padding: 1em;
      }
      tr > td > img {
        width: 100%;
        object-fit: contain;
      }
      ul {
        margin: 0;
      }
      span {
        padding: 0.5em;
        font-weight: bold;
      }

      span:hover {
        color: white;
        background-color: black;
      }
      .big-image {
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        height: 80%;
        background: white;
        z-index: 99999;
      }
    </style>
  </head>
  <body>
    <table>
      <thead>
        <tr>
          <th>Seccion</th>
          <th>Conceptos</th>
          <th></th>
        </tr>
      </thead>
      <tbody id="cuentas">
        <tr>
          <td>Cloud Computing</td>
          <td>
            - Regions are independent geographical areas composed of two or more Availability Zones. You are charged for data transferred between
            regions.<br />
            - Availability Zones are composed of one or more discrete data centers with redundant power, networking, and connectivity<br />
            - Software as a Service (SaaS) = Manage everything and provides you with a client to interact with the service <br />
            - Platform as a Service (PaaS) = Manage Applications and Data<br />
            - Pricing Model = Pay as you go<br />
            - The 3 pricing fundamentals of AWS are Compute, Storage and Data transfer out of the AWS Cloud<br />
            <b>- AWS Compute Services: </b> EC2, Lightsail, Lambda, Batch, Elastic Beanstalk, Serverless Application Repository, AWS Outposts, EC2
            Image Builder. <br />
            <b> - Types of Cloud Computing Deployments:</b>
            <ul>
              <li>Public Cloud - AWS, Azure, GCP</li>
              <li>Hybrid - Mixture of public and private</li>
              <li>Private Cloud (or On Premise) - you manage it in your datacenter</li>
            </ul>
            <b>- Advantages of Cloud Computing:</b>
            <ul>
              <li>
                Trade Capital Expense (CapEx) for variable expense: pay only when you consume resources instead of invest in data centers. No sunk
                cost.
              </li>
              <li>Benefit from massive economies of scale</li>
              <li>Stop guessing about capacity</li>
              <li>Increase speed and agility: develop faster and focus only in your code</li>
              <li>Go global in minutes</li>
            </ul>
            <b>- The costumer is responsible for the security IN the cloud: </b> security groups, IAM users, patching EC2 Operating System, patching
            DBs running in EC2,etc. <br />
            <b>- AWS is responsible for the security OF the cloud: </b> management of data centers, security cameras, cabling, patching RDS operating
            system, etc. <br />
          </td>
          <td>
            <img src="../assets/01-shared-responsibility-model.jpg.png" alt="Shared responsibiliity model" />
          </td>
        </tr>
        <tr>
          <td>IAM - Identity and Access Management</td>
          <td>
            A user can belong to one or many groups<br />
            The policies define the permissions of the user, groups or roles<br />
            When a policy is attached to an individual user is called an inline policy<br />
            <br />
            <b>MFA</b><br />
            Virtual MFA Device = Google Authenticator o Authy<br />
            U2F security key = physical USB device<br />
            <br />
            <b>How to manage AWS</b><br />
            AWS Console = UI accesible via web browser<br />
            AWS SDK = package that allow a programming language to communicate with AWS<br />
            AWS CLI = You need to install the AWS CLI and it allows you to do everything you can do in the web (AWS console).<br />
            AWS CloudShell = Is an AWS CLI that you can launch in the web browser (when you are logged in). You can upload and download files to your
            AWS PowerShell as if you are working in a machine<br />
            <br />
            <b>IAM Roles</b><br />
            They are used to assign permissions to AWS services in order to perform action on your behalf. A role can be used by either an IAM user in
            the same AWS account as the role or a user in a different AWS account. A role can also be used by a web service that AWS offers; a prime
            example is Amazon EC2.<br />
            <br />
            <b>Identities</b> <br />
            They are the IAM resource objects that are used to identify and group. You can attach a policy to an IAM identity. These include users,
            groups, and roles.<br />
            <br />
            <b>Entities</b> <br />
            They are the IAM resource objects that AWS uses for authentication. These include IAM users, federated users, and assumed IAM roles.<br />
            <br />
            <b>Principal</b> <br />
            It is a person or application that uses the AWS account root user, an IAM user, or an IAM role to sign in and make requests to AWS. <br />
            <br />
            <b>Security Tools</b><br />
            IAM Credentials Report (account-level) = a report (excel) that lists all your account's users and the status of their various
            credentials<br />
            IAM Access Advisor (user-level) = shows the services permissions granted to a user and when those services were last accessed<br />
          </td>
          <td>
            <img src="../assets/02-iam-users-groups.jpg" alt="User groups" />
            <hr />
            <img src="../assets/03-iam-policy.jpg" alt="Policies" />
            <hr />
            <span>What includes the Credentials Report</span>
            <img src="../assets/46.-credentials-report-what includes.png" alt="What includes the Credentials Report" />
          </td>
        </tr>
        <tr>
          <td>EC2 - Elastic Compute Cloud</td>
          <td>
            <b>- Budget: </b> create budget and send alarms when costs (current or forecasted) exceed the budget. Allows you to set a limit to your
            bill. You can also set actions when the thresholds are exceeded. Budget could be of three types: usage, costs or reservation.<br />
            <br />
            - This services is considered Infrastructure as a Service (IaaS). <br />
            - You can comunicate with an EC2 instance via SSH with your prefered SSH client or with the option "EC2 Instance Connect" in the console
            (web browser).<br />
            - The minimum charge for an EC2 instance is 60 seconds <br />
            <b>- Instance metadata: </b> is data about your instance that you can use to configure or manage the running instance (even
            programatically). <br />
            <br />
            <b>- EC2 user data: </b> instance bootstraping script <br />
            <br />
            <b>Amazon Machine Image (AMI)</b><br />
            docker like images to be run in EC2 instances. The AMI must be in the same region as that of the EC2 instance to be launched. If the AMI
            exists in a different region, you can copy that AMI to the region where you want to launch the EC2 instance. The region of AMI has no
            bearing on the performance of the EC2 instance. You can create a new AMI from an existing EC2 instance.<br />
            <br />
            - EC2 Image Builder. Is a free service that help you to attach packages, roles and config other options to create a custom AMI.<br />
            <br />
            <b>EC2 instance types</b><br />
            - General porpuse: ideal for web servers. Good balance between compute, memory and networking.<br />
            - Compute optimized: great for compute-intensive tasks that require high performance processors.<br />
            - Memory optimized: fast performance for workloads that process large data sets in memory.<br />
            <br />
            <b>Security groups</b><br />
            - It is (kind of) a firewall that can be attached to any EC2 instance.<br />
            - It controls how traffic is allowed into or out of our EC2 instances. Can only contain ALLOW rules.<br />
            - You can attach several security groups to an EC2 instance.<br />
            - By default a security group deny any inbound traffick and allow any outbound traffic.<br />
            <br />
            <b>EC2 Purchasing options/Launch types</b><br />
            <b>- On-Demand: </b> pay as you go<br />
            <b>- Reserved: </b> (up to 70% discount) you commit to use the instance for one or three years with no, partial or all upfront payment:
            <ul>
              <li>Standard: you cannot change the type of instance</li>
              <li>Convertible: you can change the type of instance</li>
              <li>
                Scheduled: you reserved only a specific period of the day, week or month. This is not a valid response on the exam. AWS currently has
                this messages in its web: "You cannot purchase Scheduled Reserved Instances at this time".
              </li>
            </ul>
            <b>- Spot: </b> the most cost-efficient (up to 90% discount). They use available resources of other instances thus they can be destroyed
            without prior notification.<br />
            <b>- Dedicated Instance: </b>hardware dedicated to your use but you don't have control over instance placement.<br />
            <b>- Dedicated Host: </b>physical server fully dedicated to your use. You need to commit for a 3 years period. Any question that talks
            about special licensing requirements refers to this instance type.<br />
            <br />
          </td>
          <td>
            <img src="../assets/04-EC2-instance-types.png" alt="EC2 instance types" />
            <hr />
            <img src="../assets/05-ec2-purchasing-options.png" alt="EC2 purchase options" />
            <hr />
            <img src="../assets/47.-EC2-instance-types-table.png" alt="EC2 instance types table" />
            <hr />
            <img src="../assets/48.-EC2-instance-types-Mnemonic.png" alt="EC2 instance types Mnemonic" />
          </td>
        </tr>
        <tr>
          <td>EC2 - Solutions Architect Associate Level</td>
          <td>
            <b>- Types of IPs:</b>
            <ul>
              <li><b>Private IP: </b> You can use it internally in your network but not in the internet.</li>
              <li><b>Public IP: </b> You can use it to connect to the internet.</li>
              <li>
                <b>Elastic IP: </b> AWS offers (for rent) Public IPs that you can attach to an EC2 instance or other service in order to have a pubilc
                static IP no matter if the instance is restarted.
              </li>
            </ul>
            <br />
            <b>- Spot Fleet:</b> is a set of Spot Instances and optionally On-demand Instances. It allows you to automatically request Spot Instances
            with the lowest price. <br />
            <b>- EC2 Placement Groups:</b> It allows you to control the EC2 instances placement. When you create a placement group you can specify one
            of these strategies:
            <ul>
              <li>
                <b>Cluster: </b> clusters instances into a low latency group in a single AZ. Good for applications that need low latency but has the
                con of low availability
              </li>
              <li>
                <b>Spread: </b> spread instances across underlying hardware - racks (max 7 instances per group per AZ). Good for applications that
                needs high availability but has the con of a higher latency.
              </li>
              <li>
                <b>Partition: </b> spread instances across many different partitions (which rely in different sets of racks) within an AZ. Scales to
                hundreds of EC2 instances per group. Good for big data applications which are partition aware.
              </li>
            </ul>
            <br />
            <b>- Elastic Network Interfaces (ENI):</b> Logical component in a VPC that represents a virtual netwrk card. It's bound to a specific AZ.
            You can created it attached to an EC2 instance (it's deleted when the instance is terminates) or on the fly in order to attach it to an
            EC2 instances or another one for failover. It can have th following attributes:
            <ul>
              <li>Primary private IPv4 and one or more secondary IPv4</li>
              <li>One elastic IPv4 per private IPv4</li>
              <li>One public IPv4</li>
              <li>One or more security groups</li>
              <li>A MAC address</li>
            </ul>
            <br />
            <b>- EC2 Hibernate:</b> It help you to have shorter instance start times placing the in-memoty (RAM )state in the attached EBS volume (the
            volumen must be an EBS and it must be encrypted). Is available for on-demand, reserved and spot instances. Not supported for are metal
            instances
            <br />
          </td>
          <td>
            <img src="../assets/57.-ec2-placement-group-cluster.png" alt="EC2 Placement Group Cluster" />
            <hr />
            <img src="../assets/58.-ec2-placement-group-spread.png" alt="EC2 Placement Group Spread" />
            <hr />
            <img src="../assets/59.-ec2-placement-group-partition.png" alt="EC2 Placement Group Partition" />
            <hr />
            <img src="../assets/60.-ec2-hibernate.png" alt="EC2 Hibernate Process" />
          </td>
        </tr>
        <tr>
          <td>EC2 Instance Storage</td>
          <td>
            <b>EBS - Elastic Block Storage</b><br />
            - Is a network drive you can attach to your instances while they run (might be a bit of latency)<br />
            - The first EBS volumen attached to an EC2 instance is considered a root volume and its default behaviour is to be deleted on EC2 instance
            termination. If you have more tha one EBS volume attached t the same instance the default behaviour (delete volume) is only applied to the
            root volume. <br />
            - Is a recommended storage option when you run databases on an instance <br />
            - Can be attached to only one EC2 instance at a time but one instance can have several EBS volumes attached<br />
            - Only work in one availability zone. You can create a snapshot to migrate a volume from one AZ to another<br />
            - About volume type: gp2 and gp3 are general porpuse volumes. io1 and io2 are great for operations that needs high I/O operations per
            second. HDD is good if you are looking for a cheaper solution and the performance is not your main concern. <br />
            - Only EBS volume types gp2, gp3, io1 and io2 can be used as boot volumes <br />
            - Multi-attach: an io1 or io2 EBS volume can be attached to multiple instances in the same AZ. Can attach up to 16 instances at a time.
            Must use a filesystem that is cluster aware<br />
            - gp2 and gp3 increase its I/O when storage size is increased. io1 and io2 increase its I/O independently. <br />
            - You can create an encrypted EBS volume (all the encryption is handled by AWS leveraging KMS keys) which means encryption of data inside
            the volume, all data in-flight between volume and instance, snapshot and volumes created from an ecrypted snapshot. <br />
            - Amazon EBS Snapshots are a point in time copy of your block data. For the first snapshot of a volume, Amazon EBS saves a full copy of
            your data to Amazon S3. EBS Snapshots are stored incrementally, which means you are billed only for the changed blocks stored. <br />
            <br />
            <b>EC2 Instance Store</b><br />
            - Is a high performance block storage attached to an EC2 instance. Is ephemeral, is deleted when the EC2 instance is terminated.<br />
            <br />
            <b>EFS - Elastic File System</b><br />
            - Is an elastic file system for Linux-based workloads <br />
            - No upfront payments. You pay for the amount of data (per GB) that you use <br />
            - Can be mounted in hundreds of EC2 instances even if they belong to multiple AZs.<br />
            - Can be directly used with on-premises systems. <br />
            - Offers high availability, scalability but at a higher cost (3x expensive than EBS gp2). EC2 instances can access files on an EFS file
            system across many Availability Zones, Regions and VPCs<br />
            - It has an Infrequent Access storage Class that is cost-optimized for files accessed less frequently. Data stored on the Infrequent
            Access storage class costs less than Standard and you will pay a fee each time you read from or write to a file. <br />
            <br />
            <b>FSx</b><br />
            - FSx for Windows File Server is a fully managed, highly reliable, and scalable Windows native shared file system.<br />
            - FSx for Lustre (Linux and Cluster) is a fully managed high peformance, scalable file storage for High Performance Computing (HPC). It
            can scale to hundreds of GB/s.
          </td>
          <td>
            <span>EBS snapshot features</span>
            <img src="../assets/61.-ebs-snapshot-features.png" alt="EBS snapshot features" />
            <hr />
            <span>EBS drive type</span>
            <img src="../assets/49.-EBS-drive-types.png" alt="EBS drive type" />
            <hr />
            <span>EFS storage classes</span>
            <img src="../assets/62.-efs-storage-classes.png" alt="EFS storage classes" />
            <hr />
            <span>EFS performance classes</span>
            <img src="../assets/63.-efs-performance-classes.png" alt="EFS performance classes" />
            <hr />
            <img src="../assets/06-EC2-storage.png" alt="EC2 purchase options" />
          </td>
        </tr>
        <tr>
          <td>High Availability and Scalability: Elastic Load Balancer (ELB) and Auto Scaling Grouops (ASG)</td>
          <td>
            - Horizontal scalability = elasticity <br />
            - High availability = run your application or system in at least two data centers <br />
            <br />
            <b>Elastic Load Balancer - ELB</b><br />
            - Provide SSL for several EC2 instances<br />
            - Do regular health checks to your instances<br />
            - Some load balancer can be setup as internal (private) or external (public) <br />
            - The most secure way of ensuring only the ALB can access the EC2 instances is referencing the ALB by security group in rules. <br />
            - AWS offers three kind of load balancers:
            <ul>
              <li>
                Classic load balancer - CLB (slowly retiring) - layer 4 & 7: when created receive a fixed hostname (XXX.region.elb.amazonaws.com). In
                order to add targets you need to add them directly to the load balancer's configuration (not using target group). Can make health
                checks via HTTP, HTTPS or TCP protocols. Provides static DNS
              </li>
              <li>
                <b>Application load balancer - ALB (HTTP / HTTPS only) - layer 7:</b> you can set a target group that list the EC2 instances, ECS
                tasks, lambda functions o IP Addresses where is going to route the traffic to. It can route to differente target groups. The health
                checks are at target group level. You can configure responses from the load balancer, is not required to route to a target group.
                Provides static DNS. To get the client's IP address, ALB adds an additional header called "X-Forwarded-For", it contains the client's
                IP address
              </li>
              <li>
                <b>Network load balancer - NLB (ultra high performance, allows for TCP and UDP) - layer 4:</b> less latency than Application load
                balancer and can handle millions of requestsper second. Has one static IP per AZ and supports assigning elactic IP (helpful for
                whitelisting specific IP). Their target groups support EC2 instances, IP addresses (only private IPs) and Application load balancer.
                Can make health checks via HTTP, HTTPS or TCP protocols. Only Network Load Balancer provides both static DNS name and static IP.
              </li>
              <li>
                <b>Gateway load balancer - GLB - layer 3 (network layer) IP Protocol:</b> deploy, scale and manage a fleet of 3rd party netwotk
                virtual appliances (for example: firewalls, intrusion detection systems, payload manipulation, etc). It's normally used in combination
                with oter type of load balancer (see image).Uses the GENEVE prtotocol on port 6081. Their target groups support EC2 instances and IP
                addresses (only private IPs). Combine the following functions: Transparent network gateway (single exit/entry for all traffic) and
                Load balancer (distributes trafic to your virtual appliances)
              </li>
            </ul>
            - During the ELB config process you can:
            <ul>
              <li>Make the ALB available in different subnetworks (ACs)</li>
              <li>Attach security groups</li>
              <li>Set the http port that the ALB is listening to</li>
              <li>Set the Target Group (group of EC2 instances) for the ALB to redirect the traffic</li>
            </ul>
            - Sticky sessions (session affinity): is possible to implement stickiness so that the same client is always redirected to the same
            instance behind a load balancer. This works for classic load balancer and application load balancer. A use case for this feature could be
            make sure the user doesn't lose his session data. The stickiness is controlled with a cookie that can be generated by the target or the
            load balancer, in both cases you can set the duration of the cookie (from 1 second to 7 days). <br />
            - Cross-zone load balacing: allows you to route the traffic to more than one AZ. See image for more details for each loadb balancer
            type<br />
            - SSL - Server Name Indication (SNI): SNI solves the problem of load multiple SSL certificates onto one web server (to serve ultiple
            websites). It requires the client to indicate the hostname of the target server in the initial SSL handshake in order to provide the right
            certificate. It only works for ALB and NLB, to apply multiple SSL certificates with CLB you must create multiple CLB<br />
            - Connection drainning (for CLB) or Deregistration Delay (for ALB and NLB): use it to ensure that a Load Balancer stops sending requests
            to instances that are de-registering or unhealthy, while keeping the existing connections open. This enables the load balancer to complete
            in-flight requests made to instances that are de-registering or unhealthy. When you enable connection draining, you can specify a maximum
            time for the load balancer to keep connections alive before reporting the instance as de-registered. The maximum timeout value can be set
            between 1 and 3,600 seconds (the default is 300 seconds). When the maximum time limit is reached, the load balancer forcibly closes
            connections to the de-registering instance <br />
            <br />
            <b>Auto Scaling Groups - ASG</b><br />
            - Scale out means add instances. Scale in means remove instances<br />
            - You can set a minimum, maximum and desired size and the ASG scales accordingly. This configuration is called an scaling policy<br />
            - The goal is to setup as many EC2 instances as you set in the desired size without breaking the minimum and maximum sizes (limits)<br />
            - It can replace an unhealthy instance and register new instances to a load balancer<br />
            - After a scaling activity happens, you are in the cooldown period (default to 300 seconds). During the cooldown period the ASG will not
            launch or terminate additional instances (to allow for metrics to stabilize) <br />
            - Good metrics to scale on: CPU utilization, request count per target, average network in / out, custom metrics that better fit your use
            case <br />
            - Scaling Strategies:<br />
            <ul>
              <li>Manual Scaling: manually set the ideal sizes</li>
              <li>
                Dynamic Scaling:<br />
                <b>- Simple / Step Scaling: </b> set alarms in CloudWatch and when the alarm is triggered then add or remove instances. <br />
                <b>- Target tracking scaling: </b> tracks a metric. For example: I want the average ASG CPU to stay at around 40%. <br />
                <b>- Scheduled scaling: </b> anticipate a scaling based on known usage patterns. For example: Increase the min capacity at 5pm on
                fridays. <br />
              </li>
              <li>
                Predictive Scaling: use machine learning to predict future traffic ahead of time and automatically provisions the necessary EC2
                instances
              </li>
            </ul>
          </td>
          <td>
            <span>Gateway Load Balancer Infra Example</span>
            <img src="../assets/64.-gateway-load-balancer.png" alt="Gateway Load Balancer Infra Example" />
            <hr />
            <span>Cross-zone load balancing</span>
            <img src="../assets/65.-cross-zone-load-balancing.png" alt="Cross-zone load balancing" />
            <hr />
            <img src="../assets/08-auto-scaling-group.png" alt="Auto Scaling Group" />
            <hr />
            <img src="../assets/09-AG-Scaling-Strategies.png" alt="Auto Scaling Strategies" />
          </td>
        </tr>
        <tr>
          <td>AWS Fundamentals: RDS + Aurora + ElastiCache</td>
          <td>
            <b>RDS</b> <br />
            - Stands for Relational Database Service. It's a managed DB service <br />
            - It allows you to create DBs in the cloud that are managed by AWS <br />
            - You can't SSH into an RDS instance <br />
            - Support the following RDBMS: Postgres, Mysql, Mariadb, oracle or sql server <br />
            - Support storage auto scaling: helps you increase your DB storage dynamically. You hace to set maximum storage threshold (maximum limit
            for DB storage). Automatically modify storage if: free storage is less than 10% of allocate storage, low-storage lasts at least 5 minutes
            and 6 hours have passed since last modification <br />
            - Read replicas: it's main porpuse is scale the read capacity of your database (not availability). The replicas update is asynchronous
            (eventual consistency). You can have up to 5 read replicas. In AWS there is a cost when data goes from one AZ to another, for RDS within
            the same region you don't pay this fee. Read replicas add new endpoints with their own DNS name. We need to change our application to
            reference them individually to balance the read load. You can't create encrypted read replicas for an uncreypted database<br />
            - Multi AZ (disaster recovery): it's main porpuse is increase availability (not used for scaling) creating a failover DB that is always up
            to date (data replication is synchronous). The key part is the DNS name for the DB that allows the use of the failover in case of failure.
            You can change from a Single-AZ to a Multi-AZ configuration with zero downtime, internally AWS create the failover DB from a snapshot of
            the original DB and set up the syncronization between them. Also a read replica can be set up as Multi AZ for disaster recovery<br />
            - Advantages of using RDS over configure a DB on an EC2 instance by yourself:
            <ul>
              <li>Automated provisioning (OS patching</li>
              <li>Continuous backups and restore to specific timestamp (Point in time restore)</li>
              <li>Monitoring dashboard</li>
              <li>Read replicas for improved read performance</li>
              <li>Multi AZ setup for DR (disaster recovery)</li>
              <li>Maintenance windows for upgrades</li>
              <li>Scaling capability</li>
              <li>Storage backed by EBS (gp2 or io1)</li>
            </ul>
            - RDS Custom (only for Oracle and SQL Server): gives you acces to the underlying database an OS so you can: configure settings, install
            patches, enable native features or even access the underlying EC2 instance using SSH or SSM (Session Manager). To perform your
            customizations is recommended to deactivate Automation Mode and even take a DB snapshot before any custom change. <br />
            - RDS Backups: you can manually create a DB snapshot and the retention of this backup is as long as you want. When activate automated
            backup you have daily full backup of the database (during the maintenance window), transaction logs are backed-up by RDS every 5 minutes,
            ability to restore to any point in time (from oldest backup to 5 minutes ago) and 1 to 35 days of retention (set to 0 to disable automated
            backups). <br />
            Trick: In a stopped RDS database, you will still pay for storage. If you plan on stopping it for a long time, you should snapshot and
            restore instead. <br />
            <br />
            <b>Aurora</b> <br />
            - It's a propietary technology of AWS optimized for the cloud (performance improvement - 5x over MySQL and 3x over PostgreSQL). <br />
            - Only supports MySQL and PostgreSQL. It doesn't support MariaDB. <br />
            - Is 20% more expensive than RDS but also more efficient. <br />
            - Its storage grows automatically in increments of 10GB up to 12 8TB. <br />
            - Can have up to 15 replicas and the replication process is faster (sub 10ms). <br />
            - Have one Writer Endpoint that internally points to the master node (the only one that can write) and one Reader Endpoint that load
            balance the client's connections to the read replicas. <br />
            - The master (writer) node is replaced with any read replica on failure. <br />
            - Read replica auto scaling: based on CPU usage <br />
            - Custom endpoints: allows you to control which read replica responds to each custom endpoint you create. <br />
            - Aurora serverless: automatic instantiation and auto scaling based on actual usage. The client connect to "Proxy fleet" (managed by
            Aurora) and it scales the DB based on current usage. <br />
            - Aurora Multi-master: the default failover mechanism promotes a read replica as the new master. With multi-master every node does reads
            and writes which gives you the ability to inmediately failover from one node to another. <br />
            - Global Aurora: see image. It offers Aurora as a global (multi region) service. Typical cross-region replication takes less than one
            second. <br />
            - Aurora Machine Learning: simple, optimized, and secure integration between Aurora and AWS ML Services (Amazon SageMaker, Amazon
            Comprehend) <br />
            - To manually delete your Aurora cluster, you first need to delete all the read and write replicas. <br />
            - Aurora Backups: you can manually create a DB snapshot and the retention of this backup is as long as you want. When enable automated
            backups you can choose between 1 to 35 days of retention and once enabled it can't be disabled. The automated backups offers you point in
            time recovery based on the retention days you configure. <br />
            -Aurora Database Cloning: create a new aurora cluster form an existing one faster than snapshot and restore. Useful to create staging
            databases from a production one without impacting performance.<br />
            <br />
            - RDS / Aurora Restore options: restoring a backup or a snapshot creates a new database. Restoring from an S3 bucket creates a new
            database. <br />
            - RDS / Aurora security:
            <ul>
              <li>
                <b>At rest encryption:</b> is managed using AWS KMS (must defined at launch time). If the master is not encypted the read replicas
                cannot be encrypted. To encrypt an unencrypted database go through a DB snapshot and restore as encrypted
              </li>
              <li><b>In-flight encryption:</b> TLS-ready by default, use the AWS TLS root certificates client-side</li>
              <li>
                <b>IAM Authentication:</b> you can use IAM roles to connect to your database (instead of username / password). Not supported by Oracle
                databases.
              </li>
              <li><b>Security groups:</b> use it to control network access to your RDS / Aurora database</li>
              <li><b>No SSH available:</b> the only exception is RDS Custom</li>
              <li><b>Audit logs:</b> can be enabled and sent to CloudWatch Logs for longer retention</li>
            </ul>
            <br />
            <b>RDS Proxy</b> <br />
            - Fully managed database proxy for RDS. Serverless, autoscaling, highly available (multi-AZ) <br />
            - Support RDS (MySQL, Postgres, MariaDB) and Aurora (MySQL, Postgres) <br />
            - No code changes required for most apps <br />
            - Allows app to pool an share connections established with the database <br />
            - Improve database efficiency by reducing the stress on database resources (CPU, RAM) and minimize open connections (timeouts) <br />
            - Reduced RDS and Aurora failover time by up to 66% <br />
            - Enforce IAM authentication for database and securely store credentials in AWS Secrets Manager <br />
            - It's never plublicly accesible. Must be accessed from VPC <br />
            <br />
            <b>ElastiCache</b> <br />
            - Fully managed service for Redis and MemCached <br />
            - AWS takes care of OS maintenance / patching, optimizations, setup, configuration, monitorign, failure recovery and backups <br />
            - Usign ElastiCache involves heavy application code changes <br />
            - Do not support IAM authentication. IAM policies in ElastiCache are only used for AWS API-level security <br />
            - You can set an token / password when you create a Redis cluster. This is an extra level of security for your cache (on top of security
            groups) <br />
            - Redis support SSL in-flight encryption <br />
            - MemCached support SASL-based authenticaiton <br />
            - Patterns for ElastiCache:
            <ul>
              <li>
                <b>Lazy loading:</b> all the read data is cached, data can become stale in cache. Only when you don't have an entry in the cache the
                request pass to the actual database
              </li>
              <li><b>Write through:</b> adds or update data in the cache when written to a DB (no stale data)</li>
              <li><b>Session store:</b> store temporary session data in cache (using TTL features)</li>
            </ul>
            <br />
            <b>Important ports:</b> <br />
            - FTP: 21 <br />
            - SSH: 22 <br />
            - SFTP: 22 (same as SSH) <br />
            - HTTP: 80 <br />
            - HTTPS: 443 <br />
            - PostgreSQL: 5432 <br />
            - MySQL: 3306 <br />
            - Oracle RDS: 1521 <br />
            - MSSQL Server: 1433 <br />
            - MariaDB: 3306 (same as MySQL) <br />
            - Aurora: 5432 (if PostgreSQL compatible) or 3306 (if MySQL compatible)
          </td>
          <td>
            <span>RDS Read Replicas</span>
            <img src="../assets/66.-rds-read-replicas.png" alt="RDS Read Replicas" />
            <hr />
            <span>RDS Multi AZ</span>
            <img src="../assets/67.-rds-multi-az.png" alt="RDS Multi AZ" />
            <hr />
            <span>Aurora Features</span>
            <img src="../assets/69.-aurora-features.png" alt="Aurora Features" />
            <hr />
            <span>Global Aurora</span>
            <img src="../assets/70.-aurora-global.png" alt="Global Aurora" />
            <hr />
            <span>Aurora Machine Learning</span>
            <img src="../assets/71.-aurora-machine-learning.png" alt="Aurora Machine Learning" />
            <hr />
            <span>Redis vs MemCached</span>
            <img src="../assets/72.-redis-vs-memcached.png" alt="Redis vs MemCached" />
          </td>
        </tr>
        <tr>
          <td>Route 53</td>
          <td>
            You can check the existing of a DNS record with the following command line utils: nslookup (hostname) or dig (hostname) <br />
            <b>- DNS:</b> Domain Name System which translates the human friendly hostnames into the machine IP addresses. When you make a request with
            a human friendly hostname the DNS searches for the corresponding IP in a recursive way, from the root (right-most part of the url) to the
            domain name (left-most part of the url). <br />
            <b>- Domain Registrars (and 3rd party domains):</b> an organization that allows you to purchase and register domain names (Amazon,
            NameCheap, GoDaddy, etc.). The AWS registrar is called Amazon Registrar Inc. You can use Route53 just as a DNS service with a 3rd party
            domain or register your domain with AWS. In order to setup a 3rd party domain with Route53 you need to create a hosted zone an then change
            the DNS nameservers (NS records) in the domain registrar for the nameservers of the hosted zone in order to be able to manage the DNS
            record from the AWS console.
            <br />
            <b>Time To Live - TTL:</b> represents the time that an entry is going to be cached in the client to avoid request the DNS too often. If
            you set a high TTL the DNS (Route53) will receive less traffic but have the problem of outdated records whenever you need to change an IP
            address. If you set a low TTL your DNS is going to receive a lot of request which means a higher cost (Route53 charge you depending on the
            traffic). The TTL is mandatory for all types of records, except alias. <br />
            <b>- Hosted Zones:</b> a container for DNS records that define how to route traffic to a domain and its subdomains. It responds to DNS
            queries with the corresponding IP address. When you register (purchase) a domain, it automatically generate a hosted zone with its
            correspondingNS record. The cost for each hosted zone is 0,50 dollars per month. There are two types of hosted zones:
            <ul>
              <li>
                Public: for public domain names you can create a public hosted zone which contains records that specify how to route traffic on the
                internet
              </li>
              <li>
                Private: for private domain names you can create a private hosted zone which contains records that specify how to route traffic within
                one or more VPCs
              </li>
            </ul>
            <b>- Route 53:</b> it's a highly available, scalable, fully managed and authoritative (means you can update the DNS records) DNS. It's
            also a domain registrar. It has the ability t check the health of your resources. it's considered the only AWS service that provides 100%
            availability SLA. It's name is a reference to the traditional DNS port. Each DNS (Route53) record contains:
            <ul>
              <li>Domain/subdomain name: e.g. example.com</li>
              <li>Record type: e.g. A or AAAA</li>
              <li>Value: the IP address</li>
              <li>Routing Policy: how Route 53 reponds to queries</li>
              <li>TTL: amount of time the record cache at DNS resolvers</li>
            </ul>
            - DNS record types:
            <ul>
              <li>A: maps a hostname to IPv4</li>
              <li>AAAA: maps a hostname to IPv6</li>
              <li>AAAA: maps a hostname to IPv6</li>
              <li>CNAME: maps a hostname to another hostname. The target must have an A or AAAA record. Only works fot NON root domains</li>
              <li>
                Alias: is a record specific for Route53. Points a hostname to an AWS Resource.It works for root domains and non root domains. It's
                free of charge and offers native health check. An alias record is always of type A or AAAA for AWS resources. You can't set the TTL
                for this type of record, it's set automatically by Route53. You cannot set an alias for an EC2 DNS alias. See image for a list of
                possible targets for this type of record
              </li>
              <li>
                NS: Name Server for the hosted zone. Control how traffc is routed for a domain. Its is the DNS names or IP adresses of the servers you
                want to responds to the received queries for your hosted zone
              </li>
            </ul>
            - Health Checks: they are mainly for public resource. Health checks only pass when receive 2xx or 3xx status codes. Health checks can be
            set to pass / fail based on text in the first 5120 bytes of the response. Your firewall (e.g. security groups) needs to allow the Route53
            health checks request. Health checks are integrated with CloudWatch so you can have health checks metrics. The Route53 health checks can
            monitor three types of resource:
            <ul>
              <li>
                An endpoint: about 15 health checkers will check the endpoint health, if more than 18% of health checkers report the endpoint is
                healthy, Route53 considers it "healthy", otherwise is "unhealthy". You can set the interval for the health checks and a threshold
                (default is 3) that represents the times that health check result needs to be unhealthy in order to be marked the endpoint as
                unhealthy. Support TCP, HTTP and HTTPS. You have the ability to choose shich locations you want Route53 to use.
              </li>
              <li>
                Other Route53 health checks (calculated health checks): combine the results of multiple health checks into a single health check. You
                can use choose options based on logical operator such as AND, OR and NOT. It can monitor up to 256 child health checks. You need to
                specify how many child health checks need to pass in order to mark the resource as healthy
              </li>
              <li>
                CloudWatch metric (e.g. Dynamo throttle): they are useful to ealth check private hosted zones because Route53 health checkers are
                outside the VPC and they can't access private endpoints. In order to monitor private resources, you can create a CloudWatch Metric and
                associate a CloudWatch Alarm, then create a health check that checks the alarm itself
              </li>
            </ul>
            - Routing Policies: <br />
            It doesn't refer to actual routing, like the load balancer routing. It refers to the info that is returned for a received DNS query:
            <ul>
              <li>
                Simple: route traffic to a simple resource. Can specify multiple values and the client pick one of them randomly. It can't be
                associated with health checks
              </li>
              <li>
                Weighted: control the percentage of the requests that go to each resource (weight don't need to sum up to 100%). DNS records must have
                the same name and type. Can be associated with health checks. When assign weight 0 to a record Route53 stop to send traffic to that
                resource but if all records have weight 0, then all record will be returned equally
              </li>
              <li>
                Latency Based: redirect to the resource that has the least latency. Latency is based on traffic between users and AWS regions, so you
                need to select the region against the latency is going to be measured. Can be associated with health checks. Has a failover capability
              </li>
              <li>
                Failover: it switch the Ip address to the failver resource based on the status of a Route53 health check that you need to create
                beforehand. To set up a failover you create two A or AAAAA records, one marked as Primary and the failover marked as Secondary, both
                records needs to have same record name.
              </li>
              <li>
                Geolocation: on configuration specify location by continent, country or US state and the DNS is going to route the traffic to the
                specified IP address based on where the user is actually located - match with the configured location (if there's overlapping more
                precise location is selected). You should create a record with location = default in case thre's no match on location. Can be
                associated with health checks
              </li>
              <li>
                Geoproximity (using Route53 traffic flow feature): similar to geolocation but you can assign a "bias" to each record. The bias add
                more weight to the record when routing traffic so you can control the amount of traffic that is going to be routed to the specified
                resource based on user location and bias. The bias can be set from -99 (negative values) to 99. See images.
              </li>
              <li>
                Multi-value answer: used when routing traffic to multiple resources. Route53 return multiple values/rsources. Can be associated with
                health checks (return only values marked as healthy). up to 8 healthy values can be returned for eahc multi-value query. This is not a
                substitute for a load balancer because the idea is that the client can load balance (default behaviour when a client receive multiple
                values for a single record), not your backend
              </li>
            </ul>
          </td>
          <td>
            <span>DNS Terminologies</span>
            <img src="../assets/73.-dns-terminologies.png" alt="DNS Terminologies" />
            <hr />
            <span>Route53 Hosted Zones</span>
            <img src="../assets/74.-route53-hosted-zones.png" alt="Route53 Hosted Zones" />
            <hr />
            <span>Alias record targets</span>
            <img src="../assets/75.-route53-alias-record.targets.png" alt="Alias record targets" />
            <hr />
            <span
              >Geoproximity routing policy - to a user that has the same (or similar) geoproximity to both resources (DNS records) the bias helps you
              redirect traffic to the region with higher bias</span
            >
            <img src="../assets/76.-route53-geoproximity-routing-policy.png" alt="Geoproximity routing policy" />
          </td>
        </tr>
      </tbody>
    </table>
    <script>
      const imgNodeList = document.querySelectorAll('img')

      Array.from(imgNodeList).forEach(function (imgNode) {
        imgNode.addEventListener('click', toggleBigImage)
      })

      function toggleBigImage(e) {
        e.target.classList.toggle('big-image')
      }
    </script>
  </body>
</html>
